# Plano de Implementa√ß√£o - Ambiente Vetorizado CityLearn

## ‚úÖ Fase 1: An√°lise e Planejamento (Conclu√≠da)

### Documenta√ß√£o Criada
- ‚úÖ **README.md**: Vis√£o geral e arquitetura do ambiente
- ‚úÖ **architecture.md**: Diagramas Mermaid e fluxos de dados
- ‚úÖ **config.md**: Configura√ß√µes YAML detalhadas
- ‚úÖ **specifications.md**: Especifica√ß√µes t√©cnicas completas

### An√°lise Realizada
- ‚úÖ **Datasets**: 6 datasets analisados (2022 e 2023 phases)
- ‚úÖ **Features**: 28 features por pr√©dio categorizadas
- ‚úÖ **Compatibilidade**: SB3, Gymnasium, VecEnv
- ‚úÖ **KPIs**: M√©tricas de performance identificadas

## üöß Fase 2: Implementa√ß√£o Base (Em Progresso)

### 2.1 CityLearnVecEnv - Classe Principal

**Status**: Planejado
**Prioridade**: Alta
**Local**: `src/environment/citylearn_vec_env.py`

```python
class CityLearnVecEnv(gymnasium.Env):
    """Ambiente vetorizado multi-agente para CityLearn"""

    def __init__(self, dataset_name, reward_function="cooperative", **kwargs):
        # Inicializa√ß√£o do ambiente CityLearn
        # Configura√ß√£o de espa√ßos
        # Setup de comunica√ß√£o

    def reset(self, **kwargs):
        # Reset vetorizado
        # Concatena√ß√£o de observa√ß√µes

    def step(self, actions):
        # Execu√ß√£o multi-agente
        # C√°lculo de recompensas cooperativas
```

### 2.2 Sistema de Recompensas

**Status**: Planejado
**Prioridade**: Alta
**Local**: `src/environment/rewards.py`

```python
class CooperativeReward:
    """Sistema de recompensas cooperativas"""

    def __init__(self, weights=None):
        self.weights = weights or {
            "comfort": 0.25,
            "cost": 0.25,
            "peak": 0.25,
            "cooperation": 0.25
        }

    def __call__(self, observations, actions, info):
        # Recompensa local (conforto + custo)
        # Recompensa global (pico + emiss√µes)
        # B√¥nus de coopera√ß√£o
        return combined_reward
```

### 2.3 Sistema de Comunica√ß√£o

**Status**: Planejado
**Prioridade**: M√©dia
**Local**: `src/environment/communication.py`

```python
class CommunicationProtocol:
    """Protocolo de comunica√ß√£o entre agentes"""

    def __init__(self, comm_type="full"):
        self.type = comm_type  # "full", "neighborhood", "centralized"

    def send_message(self, sender_id, receiver_id, message):
        # Envio de mensagens entre agentes

    def receive_messages(self, agent_id):
        # Recep√ß√£o de mensagens
```

## üìã Fase 3: Integra√ß√£o e Testes

### 3.1 Factory Functions

**Status**: Planejado
**Local**: `src/environment/factory.py`

```python
def make_citylearn_vec_env(dataset_name="citylearn_challenge_2022_phase_1",
                          reward_function="cooperative",
                          communication=True,
                          **kwargs):
    """Factory function para criar ambientes configurados"""
    return CityLearnVecEnv(...)
```

### 3.2 Wrappers de Compatibilidade

**Status**: Planejado
**Local**: `src/environment/wrappers.py`

```python
class SB3CompatibilityWrapper(gymnasium.Wrapper):
    """Wrapper para compatibilidade com Stable Baselines3"""

    def __init__(self, env):
        super().__init__(env)
        # Configura√ß√µes espec√≠ficas do SB3

class RewardNormalizationWrapper(gymnasium.Wrapper):
    """Wrapper para normaliza√ß√£o de recompensas"""
```

### 3.3 Testes Unit√°rios

**Status**: Planejado
**Local**: `tests/unit/test_environment.py`

```python
def test_environment_creation():
    """Testa cria√ß√£o do ambiente"""
    env = make_citylearn_vec_env()
    assert env.num_buildings == 5
    assert env.observation_space.shape == (140,)

def test_reward_functions():
    """Testa fun√ß√µes de recompensa"""
    env = make_citylearn_vec_env(reward_function="cooperative")
    # Testes de recompensa
```

## üîß Fase 4: Configura√ß√£o e Utilit√°rios

### 4.1 Configura√ß√£o YAML

**Status**: Documentado
**Local**: `config/citylearn_vec_env.yaml`

```yaml
environment:
  name: "CityLearnVecEnv"
  dataset: "citylearn_challenge_2022_phase_1"

  reward:
    type: "cooperative"
    weights:
      comfort: 0.25
      cost: 0.25
      peak: 0.25
      cooperation: 0.25

  communication:
    enabled: true
    type: "full"
```

### 4.2 Utilit√°rios

**Status**: Planejado
**Local**: `src/environment/utils.py`

```python
def validate_config(config):
    """Valida configura√ß√£o do ambiente"""
    # Valida√ß√µes de par√¢metros

def load_config(config_path):
    """Carrega configura√ß√£o de arquivo YAML"""
    # Carregamento e valida√ß√£o

def create_env_from_config(config):
    """Cria ambiente a partir de configura√ß√£o"""
    # Factory a partir de config
```

## üìä Fase 5: Valida√ß√£o e Benchmarking

### 5.1 M√©tricas de Performance

**Status**: Planejado
**Local**: `src/environment/benchmark.py`

```python
def benchmark_performance(env, num_episodes=100):
    """Benchmark de performance do ambiente"""
    # Medi√ß√£o de throughput
    # An√°lise de uso de mem√≥ria
    # Profiling de opera√ß√µes

def compare_baselines(env, algorithms=["PPO", "SAC", "MADDPG"]):
    """Compara√ß√£o com baselines"""
    # Treinamento e avalia√ß√£o
    # Gera√ß√£o de relat√≥rios
```

### 5.2 Testes de Integra√ß√£o

**Status**: Planejado
**Local**: `tests/integration/test_environment.py`

```python
def test_sb3_integration():
    """Testa integra√ß√£o com Stable Baselines3"""
    env = make_citylearn_vec_env()
    model = PPO("MlpPolicy", env)
    model.learn(total_timesteps=1000)

def test_multi_agent_cooperation():
    """Testa coopera√ß√£o entre agentes"""
    # Testes de coordena√ß√£o
    # Valida√ß√£o de comunica√ß√£o
```

## üéØ Fase 6: Documenta√ß√£o e Exemplos

### 6.1 Exemplos de Uso

**Status**: Planejado
**Local**: `examples/citylearn_vec_env_examples.py`

```python
# Exemplo b√°sico
env = make_citylearn_vec_env()
model = PPO("MlpPolicy", env)
model.learn(total_timesteps=100000)

# Exemplo avan√ßado com configura√ß√£o customizada
config = load_config("config/custom_env.yaml")
env = create_env_from_config(config)
# Treinamento avan√ßado
```

### 6.2 Documenta√ß√£o API

**Status**: Documentado
**Local**: `docs/api/environment.md`

- Documenta√ß√£o completa da API
- Exemplos de uso
- Guias de configura√ß√£o
- Troubleshooting

## üìà Roadmap de Desenvolvimento

### Sprint 1: Base Implementation (2 semanas)
- [ ] Implementar CityLearnVecEnv
- [ ] Sistema de recompensas b√°sico
- [ ] Testes unit√°rios
- [ ] Integra√ß√£o SB3

### Sprint 2: Advanced Features (2 semanas)
- [ ] Sistema de comunica√ß√£o
- [ ] Fun√ß√µes de recompensa avan√ßadas
- [ ] Wrappers de compatibilidade
- [ ] Testes de integra√ß√£o

### Sprint 3: Optimization & Validation (1 semana)
- [ ] Otimiza√ß√µes de performance
- [ ] Benchmarking
- [ ] Valida√ß√£o em todos datasets
- [ ] Documenta√ß√£o completa

## üîç Crit√©rios de Aceita√ß√£o

### Funcionalidade
- [ ] Ambiente executa sem erros
- [ ] Espa√ßos de observa√ß√£o/a√ß√£o corretos
- [ ] Fun√ß√µes de recompensa funcionais
- [ ] Compatibilidade com SB3

### Performance
- [ ] Throughput > 1000 steps/segundo
- [ ] Uso de mem√≥ria < 500MB
- [ ] Lat√™ncia < 10ms por step

### Qualidade
- [ ] Cobertura de testes > 90%
- [ ] Documenta√ß√£o completa
- [ ] Exemplos funcionais
- [ ] Valida√ß√£o em todos datasets

## üöÄ Pr√≥ximos Passos Imediatos

1. **Implementar** classe CityLearnVecEnv
2. **Criar** sistema de recompensas
3. **Desenvolver** testes unit√°rios
4. **Validar** integra√ß√£o com SB3
5. **Documentar** exemplos de uso

## üìù Notas de Implementa√ß√£o

### Depend√™ncias
- gymnasium >= 0.26.0
- citylearn >= 2.3.1
- stable-baselines3 >= 1.6.0
- numpy >= 1.21.0
- pyyaml >= 6.0

### Conven√ß√µes de C√≥digo
- Seguir PEP 8
- Type hints em todas as fun√ß√µes
- Docstrings completas
- Tratamento adequado de erros

### Versionamento
- Usar semantic versioning
- Manter compatibilidade com SB3
- Suporte a m√∫ltiplos datasets

## ü§ù Contribui√ß√£o

Para contribuir:
1. Implementar funcionalidades planejadas
2. Adicionar testes correspondentes
3. Atualizar documenta√ß√£o
4. Validar em diferentes datasets